[build-system]
requires = ["poetry-core>=1.0.0"]
build-backend = "poetry.core.masonry.api"

[tool.poetry]
name = "grl"
version = "0.1.0"
description = "Generalized Reinforcement Learning: Actions as Operators on State Space"
authors = ["Your Name <your.email@example.com>"]
readme = "README.md"
license = "MIT"
packages = [{include = "grl", from = "src"}]
keywords = ["reinforcement-learning", "neural-operators", "operator-learning", "optimal-control"]
classifiers = [
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Science/Research",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
]

[tool.poetry.dependencies]
python = ">=3.10,<3.13"

# Core ML
torch = ">=2.1"
numpy = ">=1.24"
scipy = ">=1.11"
scikit-learn = ">=1.3"

# Visualization
matplotlib = ">=3.8"
seaborn = ">=0.13"

# Utilities
tqdm = ">=4.66"
pydantic = ">=2.6"
hydra-core = ">=1.3"
omegaconf = ">=2.3"

# RL environments
gymnasium = ">=0.29"

[tool.poetry.group.operators.dependencies]
# Neural operator architectures
neuraloperator = ">=0.3"

[tool.poetry.group.baselines.dependencies]
# RL baselines for comparison
stable-baselines3 = ">=2.2"

[tool.poetry.group.experiment.dependencies]
tensorboard = ">=2.15"
wandb = ">=0.16"

[tool.poetry.group.dev.dependencies]
ipykernel = ">=6.29"
jupyter = ">=1.0"
pytest = ">=8.0"
pytest-cov = ">=4.1"
black = ">=24.0"
ruff = ">=0.3"
mypy = ">=1.8"

[tool.poetry.scripts]
grl-train = "grl.workflows.train:main"
grl-evaluate = "grl.workflows.evaluate:main"
grl-visualize = "grl.workflows.visualize:main"

[tool.black]
line-length = 100
target-version = ['py310']

[tool.ruff]
line-length = 100
target-version = "py310"

[tool.ruff.lint]
select = ["E", "F", "I", "W"]
ignore = ["E501"]

[tool.mypy]
python_version = "3.10"
warn_return_any = true
warn_unused_configs = true
ignore_missing_imports = true
