
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Physics-grounded reinforcement learning with particle-based belief representations">
      
      
        <meta name="author" content="GRL Research Team">
      
      
        <link rel="canonical" href="https://pleiadian53.github.io/GRL/GRL0/tutorials/07-rf-sarsa/">
      
      
        <link rel="prev" href="../06a-advanced-memory-dynamics/">
      
      
        <link rel="next" href="../07a-continuous-policy-inference/">
      
      
        
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>Ch 7: RF-SARSA - Generalized Reinforcement Learning (GRL)</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#chapter-7-rf-sarsa-functional-td-learning" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
      </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Generalized Reinforcement Learning (GRL)" class="md-header__button md-logo" aria-label="Generalized Reinforcement Learning (GRL)" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Generalized Reinforcement Learning (GRL)
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Ch 7: RF-SARSA
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/pleiadian53/GRL" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    pleiadian53/GRL
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../" class="md-tabs__link">
          
  
  
  GRL v0 (Tutorial Paper)

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../ROADMAP/" class="md-tabs__link">
        
  
  
    
  
  Research Roadmap

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../notebooks/" class="md-tabs__link">
          
  
  
  Notebooks

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../CONTRIBUTING/" class="md-tabs__link">
          
  
  
  About

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Generalized Reinforcement Learning (GRL)" class="md-nav__button md-logo" aria-label="Generalized Reinforcement Learning (GRL)" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Generalized Reinforcement Learning (GRL)
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/pleiadian53/GRL" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    pleiadian53/GRL
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    GRL v0 (Tutorial Paper)
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    GRL v0 (Tutorial Paper)
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Part I: Tutorials
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Part I: Tutorials
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Tutorial Index
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../00-overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Ch 0: Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../01-core-concepts/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Ch 1: Core Concepts
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../02-rkhs-foundations/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Ch 2: RKHS Foundations
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../03-energy-and-fitness/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Ch 3: Energy and Fitness
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../03a-least-action-principle/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Ch 3a: Least Action Principle
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../04-reinforcement-field/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Ch 4: Reinforcement Field
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../04a-riesz-representer/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Ch 4a: Riesz Representer
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../05-particle-memory/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Ch 5: Particle Memory
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../06-memory-update/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Ch 6: MemoryUpdate
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../06a-advanced-memory-dynamics/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Ch 6a: Advanced Memory Dynamics
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    Ch 7: RF-SARSA
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    Ch 7: RF-SARSA
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Introduction
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1-what-makes-rf-sarsa-different" class="md-nav__link">
    <span class="md-ellipsis">
      
        1. What Makes RF-SARSA Different?
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. What Makes RF-SARSA Different?">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11-classical-sarsa-a-reminder" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.1 Classical SARSA: A Reminder
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12-rf-sarsa-functional-td-in-rkhs" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.2 RF-SARSA: Functional TD in RKHS
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13-two-learning-processes-at-different-levels" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.3 Two Learning Processes at Different Levels
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-the-rf-sarsa-algorithm-informal-overview" class="md-nav__link">
    <span class="md-ellipsis">
      
        2. The RF-SARSA Algorithm (Informal Overview)
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-formal-specification" class="md-nav__link">
    <span class="md-ellipsis">
      
        3. Formal Specification
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. Formal Specification">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-notation" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.1 Notation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-algorithm-rf-sarsa" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.2 Algorithm: RF-SARSA
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33-helper-function-gpr-predict" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.3 Helper Function: GPR-Predict
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-how-rf-sarsa-works-the-three-forces" class="md-nav__link">
    <span class="md-ellipsis">
      
        4. How RF-SARSA Works: The Three Forces
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4. How RF-SARSA Works: The Three Forces">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41-temporal-credit-assignment-primitive-sarsa" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.1 Temporal Credit Assignment (Primitive SARSA)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#42-geometric-generalization-gpr" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.2 Geometric Generalization (GPR)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#43-adaptive-geometry-ard" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.3 Adaptive Geometry (ARD)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#44-the-virtuous-cycle" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.4 The Virtuous Cycle
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-connection-to-the-principle-of-least-action" class="md-nav__link">
    <span class="md-ellipsis">
      
        5. Connection to the Principle of Least Action
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5. Connection to the Principle of Least Action">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#51-rf-sarsa-as-action-minimization" class="md-nav__link">
    <span class="md-ellipsis">
      
        5.1 RF-SARSA as Action Minimization
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#52-why-this-matters-for-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        5.2 Why This Matters for Learning
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-worked-example-1d-navigation-continued" class="md-nav__link">
    <span class="md-ellipsis">
      
        6. Worked Example: 1D Navigation (Continued)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6. Worked Example: 1D Navigation (Continued)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#61-problem-setup" class="md-nav__link">
    <span class="md-ellipsis">
      
        6.1 Problem Setup
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#62-initial-state-episode-1-step-1" class="md-nav__link">
    <span class="md-ellipsis">
      
        6.2 Initial State (Episode 1, Step 1)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#63-first-experience" class="md-nav__link">
    <span class="md-ellipsis">
      
        6.3 First Experience
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#64-after-many-steps-goal-reached" class="md-nav__link">
    <span class="md-ellipsis">
      
        6.4 After Many Steps: Goal Reached
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#65-episode-2-field-guided-exploration" class="md-nav__link">
    <span class="md-ellipsis">
      
        6.5 Episode 2: Field-Guided Exploration
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#66-long-term-behavior" class="md-nav__link">
    <span class="md-ellipsis">
      
        6.6 Long-Term Behavior
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-why-rf-sarsa-is-not-standard-sarsa-with-kernels" class="md-nav__link">
    <span class="md-ellipsis">
      
        7. Why RF-SARSA Is NOT Standard SARSA with Kernels
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7. Why RF-SARSA Is NOT Standard SARSA with Kernels">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#71-common-misconception" class="md-nav__link">
    <span class="md-ellipsis">
      
        7.1 Common Misconception
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#72-what-rf-sarsa-actually-is" class="md-nav__link">
    <span class="md-ellipsis">
      
        7.2 What RF-SARSA Actually Is
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#8-relation-to-modern-rl-methods" class="md-nav__link">
    <span class="md-ellipsis">
      
        8. Relation to Modern RL Methods
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="8. Relation to Modern RL Methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#81-kernel-temporal-difference-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        8.1 Kernel Temporal Difference Learning
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#82-energy-based-rl" class="md-nav__link">
    <span class="md-ellipsis">
      
        8.2 Energy-Based RL
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#83-model-based-rl-via-gps" class="md-nav__link">
    <span class="md-ellipsis">
      
        8.3 Model-Based RL via GPs
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#84-neural-processes" class="md-nav__link">
    <span class="md-ellipsis">
      
        8.4 Neural Processes
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#9-implementation-notes" class="md-nav__link">
    <span class="md-ellipsis">
      
        9. Implementation Notes
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9. Implementation Notes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#91-choosing-hyperparameters" class="md-nav__link">
    <span class="md-ellipsis">
      
        9.1 Choosing Hyperparameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#92-computational-complexity" class="md-nav__link">
    <span class="md-ellipsis">
      
        9.2 Computational Complexity
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#93-sparse-gp-approximations" class="md-nav__link">
    <span class="md-ellipsis">
      
        9.3 Sparse GP Approximations
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#94-python-pseudocode" class="md-nav__link">
    <span class="md-ellipsis">
      
        9.4 Python Pseudocode
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#10-strengths-and-limitations" class="md-nav__link">
    <span class="md-ellipsis">
      
        10. Strengths and Limitations
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="10. Strengths and Limitations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#101-strengths" class="md-nav__link">
    <span class="md-ellipsis">
      
        10.1 Strengths
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#102-limitations" class="md-nav__link">
    <span class="md-ellipsis">
      
        10.2 Limitations
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#11-summary" class="md-nav__link">
    <span class="md-ellipsis">
      
        11. Summary
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="11. Summary">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#111-what-rf-sarsa-does" class="md-nav__link">
    <span class="md-ellipsis">
      
        11.1 What RF-SARSA Does
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#112-key-conceptual-insights" class="md-nav__link">
    <span class="md-ellipsis">
      
        11.2 Key Conceptual Insights
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#113-connection-to-the-big-picture" class="md-nav__link">
    <span class="md-ellipsis">
      
        11.3 Connection to the Big Picture
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#12-key-takeaways" class="md-nav__link">
    <span class="md-ellipsis">
      
        12. Key Takeaways
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#13-further-reading" class="md-nav__link">
    <span class="md-ellipsis">
      
        13. Further Reading
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../07a-continuous-policy-inference/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Ch 7a: Continuous Policy Inference
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Quantum-Inspired Extensions
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Quantum-Inspired Extensions
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../quantum_inspired/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../quantum_inspired/01-rkhs-quantum-parallel/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    01: RKHS-QM Parallel
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../quantum_inspired/01a-wavefunction-interpretation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    01a: Wavefunction Interpretation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../quantum_inspired/02-rkhs-basis-and-amplitudes/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    02: Basis and Amplitudes
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../quantum_inspired/03-complex-rkhs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    03: Complex RKHS
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../quantum_inspired/04-action-and-state-fields/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    04: Action and State Fields
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../quantum_inspired/05-concept-projections-and-measurements/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    05: Concept Projections
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../quantum_inspired/06-agent-state-and-belief-evolution/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    06: Agent State and Belief
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../quantum_inspired/07-learning-the-field-beyond-gp/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    07: Learning Beyond GP
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../quantum_inspired/08-memory-dynamics-formation-consolidation-retrieval/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    08: Memory Dynamics
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../quantum_inspired/09-path-integrals-and-action-principles/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    09: Path Integrals
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../implementation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Implementation Guide
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../recovering_classical_rl/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Recovering Classical RL
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ROADMAP/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Research Roadmap
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Notebooks
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Notebooks
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../notebooks/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_2" >
        
          
          <label class="md-nav__link" for="__nav_4_2" id="__nav_4_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Field Series
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Field Series
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../notebooks/field_series/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Series Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../notebooks/field_series/ROADMAP/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Roadmap
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../notebooks/field_series/00_intro_vector_fields/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    00: Introduction to Vector Fields
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../notebooks/field_series/01_classical_vector_fields/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    01: Classical Vector Fields
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../notebooks/field_series/01a_vector_fields_and_odes/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    01a: Vector Fields and ODEs
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../notebooks/field_series/02_functional_fields/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    02: Functional Fields
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_2_7" >
        
          
          <label class="md-nav__link" for="__nav_4_2_7" id="__nav_4_2_7_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Reinforcement Fields
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_2_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_2_7">
            <span class="md-nav__icon md-icon"></span>
            
  
    Reinforcement Fields
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../notebooks/field_series/03_reinforcement_fields/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../notebooks/field_series/03_reinforcement_fields/03_reinforcement_fields/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    03: Reinforcement Fields
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../notebooks/field_series/03_reinforcement_fields/03a_particle_coverage_effects/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    03a: Particle Coverage Effects
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../notebooks/field_series/03_reinforcement_fields/particle_vs_gradient_fields/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Theory: Particle vs Gradient Fields
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    About
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    About
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../CONTRIBUTING/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Contributing
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../LICENSE/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    License
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Introduction
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1-what-makes-rf-sarsa-different" class="md-nav__link">
    <span class="md-ellipsis">
      
        1. What Makes RF-SARSA Different?
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. What Makes RF-SARSA Different?">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11-classical-sarsa-a-reminder" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.1 Classical SARSA: A Reminder
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12-rf-sarsa-functional-td-in-rkhs" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.2 RF-SARSA: Functional TD in RKHS
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13-two-learning-processes-at-different-levels" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.3 Two Learning Processes at Different Levels
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-the-rf-sarsa-algorithm-informal-overview" class="md-nav__link">
    <span class="md-ellipsis">
      
        2. The RF-SARSA Algorithm (Informal Overview)
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-formal-specification" class="md-nav__link">
    <span class="md-ellipsis">
      
        3. Formal Specification
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. Formal Specification">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-notation" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.1 Notation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-algorithm-rf-sarsa" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.2 Algorithm: RF-SARSA
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33-helper-function-gpr-predict" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.3 Helper Function: GPR-Predict
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-how-rf-sarsa-works-the-three-forces" class="md-nav__link">
    <span class="md-ellipsis">
      
        4. How RF-SARSA Works: The Three Forces
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4. How RF-SARSA Works: The Three Forces">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41-temporal-credit-assignment-primitive-sarsa" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.1 Temporal Credit Assignment (Primitive SARSA)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#42-geometric-generalization-gpr" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.2 Geometric Generalization (GPR)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#43-adaptive-geometry-ard" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.3 Adaptive Geometry (ARD)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#44-the-virtuous-cycle" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.4 The Virtuous Cycle
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-connection-to-the-principle-of-least-action" class="md-nav__link">
    <span class="md-ellipsis">
      
        5. Connection to the Principle of Least Action
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5. Connection to the Principle of Least Action">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#51-rf-sarsa-as-action-minimization" class="md-nav__link">
    <span class="md-ellipsis">
      
        5.1 RF-SARSA as Action Minimization
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#52-why-this-matters-for-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        5.2 Why This Matters for Learning
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-worked-example-1d-navigation-continued" class="md-nav__link">
    <span class="md-ellipsis">
      
        6. Worked Example: 1D Navigation (Continued)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6. Worked Example: 1D Navigation (Continued)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#61-problem-setup" class="md-nav__link">
    <span class="md-ellipsis">
      
        6.1 Problem Setup
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#62-initial-state-episode-1-step-1" class="md-nav__link">
    <span class="md-ellipsis">
      
        6.2 Initial State (Episode 1, Step 1)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#63-first-experience" class="md-nav__link">
    <span class="md-ellipsis">
      
        6.3 First Experience
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#64-after-many-steps-goal-reached" class="md-nav__link">
    <span class="md-ellipsis">
      
        6.4 After Many Steps: Goal Reached
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#65-episode-2-field-guided-exploration" class="md-nav__link">
    <span class="md-ellipsis">
      
        6.5 Episode 2: Field-Guided Exploration
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#66-long-term-behavior" class="md-nav__link">
    <span class="md-ellipsis">
      
        6.6 Long-Term Behavior
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-why-rf-sarsa-is-not-standard-sarsa-with-kernels" class="md-nav__link">
    <span class="md-ellipsis">
      
        7. Why RF-SARSA Is NOT Standard SARSA with Kernels
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7. Why RF-SARSA Is NOT Standard SARSA with Kernels">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#71-common-misconception" class="md-nav__link">
    <span class="md-ellipsis">
      
        7.1 Common Misconception
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#72-what-rf-sarsa-actually-is" class="md-nav__link">
    <span class="md-ellipsis">
      
        7.2 What RF-SARSA Actually Is
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#8-relation-to-modern-rl-methods" class="md-nav__link">
    <span class="md-ellipsis">
      
        8. Relation to Modern RL Methods
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="8. Relation to Modern RL Methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#81-kernel-temporal-difference-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        8.1 Kernel Temporal Difference Learning
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#82-energy-based-rl" class="md-nav__link">
    <span class="md-ellipsis">
      
        8.2 Energy-Based RL
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#83-model-based-rl-via-gps" class="md-nav__link">
    <span class="md-ellipsis">
      
        8.3 Model-Based RL via GPs
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#84-neural-processes" class="md-nav__link">
    <span class="md-ellipsis">
      
        8.4 Neural Processes
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#9-implementation-notes" class="md-nav__link">
    <span class="md-ellipsis">
      
        9. Implementation Notes
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9. Implementation Notes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#91-choosing-hyperparameters" class="md-nav__link">
    <span class="md-ellipsis">
      
        9.1 Choosing Hyperparameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#92-computational-complexity" class="md-nav__link">
    <span class="md-ellipsis">
      
        9.2 Computational Complexity
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#93-sparse-gp-approximations" class="md-nav__link">
    <span class="md-ellipsis">
      
        9.3 Sparse GP Approximations
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#94-python-pseudocode" class="md-nav__link">
    <span class="md-ellipsis">
      
        9.4 Python Pseudocode
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#10-strengths-and-limitations" class="md-nav__link">
    <span class="md-ellipsis">
      
        10. Strengths and Limitations
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="10. Strengths and Limitations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#101-strengths" class="md-nav__link">
    <span class="md-ellipsis">
      
        10.1 Strengths
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#102-limitations" class="md-nav__link">
    <span class="md-ellipsis">
      
        10.2 Limitations
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#11-summary" class="md-nav__link">
    <span class="md-ellipsis">
      
        11. Summary
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="11. Summary">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#111-what-rf-sarsa-does" class="md-nav__link">
    <span class="md-ellipsis">
      
        11.1 What RF-SARSA Does
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#112-key-conceptual-insights" class="md-nav__link">
    <span class="md-ellipsis">
      
        11.2 Key Conceptual Insights
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#113-connection-to-the-big-picture" class="md-nav__link">
    <span class="md-ellipsis">
      
        11.3 Connection to the Big Picture
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#12-key-takeaways" class="md-nav__link">
    <span class="md-ellipsis">
      
        12. Key Takeaways
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#13-further-reading" class="md-nav__link">
    <span class="md-ellipsis">
      
        13. Further Reading
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/pleiadian53/GRL/edit/main/docs/GRL0/tutorials/07-rf-sarsa.md" title="Edit this page" class="md-content__button md-icon" rel="edit">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75z"/></svg>
    </a>
  
  


<h1 id="chapter-7-rf-sarsa-functional-td-learning">Chapter 7: RF-SARSA (Functional TD Learning)<a class="headerlink" href="#chapter-7-rf-sarsa-functional-td-learning" title="Permanent link">&para;</a></h1>
<p><strong>Purpose</strong>: Understand how GRL learns the reinforcement field through temporal-difference updates<br />
<strong>Prerequisites</strong>: Chapters 4-6 (Reinforcement Field, Particle Memory, MemoryUpdate)<br />
<strong>Key Concepts</strong>: RF-SARSA algorithm, two-layer learning, functional TD, field reshaping, belief-conditioned control</p>
<hr />
<h2 id="introduction">Introduction<a class="headerlink" href="#introduction" title="Permanent link">&para;</a></h2>
<p>We've built up the conceptual foundations:</p>
<ul>
<li>The reinforcement field <span class="arithmatex">\(Q^+(z)\)</span> as a functional object in RKHS (Chapter 4)</li>
<li>Experience particles as basis elements (Chapter 5)</li>
<li>MemoryUpdate as belief evolution (Chapter 6)</li>
</ul>
<p>But we haven't yet addressed the fundamental question: <strong>How does the agent learn <span class="arithmatex">\(Q^+\)</span> from experience?</strong></p>
<p>This chapter introduces <strong>RF-SARSA</strong> (Reinforcement Field SARSA), the core learning algorithm. The name might suggest "SARSA with kernels," but this would be misleading. RF-SARSA is fundamentally different:</p>
<table>
<thead>
<tr>
<th></th>
<th>Classical SARSA</th>
<th>RF-SARSA (GRL)</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Updates</strong></td>
<td>Scalar <span class="arithmatex">\(Q(s,a)\)</span> values</td>
<td>Particle weights defining global functional field</td>
</tr>
<tr>
<td><strong>Learning target</strong></td>
<td>State-action value</td>
<td>Geometry of the entire landscape</td>
</tr>
<tr>
<td><strong>Policy</strong></td>
<td><span class="arithmatex">\(\arg\max_a Q(s,a)\)</span></td>
<td>Field-based inference via energy minimization</td>
</tr>
<tr>
<td><strong>Generalization</strong></td>
<td>Via function approximation</td>
<td>Geometric propagation through kernels</td>
</tr>
</tbody>
</table>
<p><strong>Core insight</strong>: RF-SARSA doesn't learn Q-valuesit <strong>reshapes the energy landscape</strong> from which actions are inferred.</p>
<hr />
<h2 id="1-what-makes-rf-sarsa-different">1. What Makes RF-SARSA Different?<a class="headerlink" href="#1-what-makes-rf-sarsa-different" title="Permanent link">&para;</a></h2>
<h3 id="11-classical-sarsa-a-reminder">1.1 Classical SARSA: A Reminder<a class="headerlink" href="#11-classical-sarsa-a-reminder" title="Permanent link">&para;</a></h3>
<p>Standard SARSA (State-Action-Reward-State-Action) updates Q-values using the temporal difference (TD) error:</p>
<div class="arithmatex">\[Q(s, a) \leftarrow Q(s, a) + \alpha \left[r + \gamma Q(s', a') - Q(s, a)\right]\]</div>
<p><strong>Interpretation</strong>:</p>
<ul>
<li><strong>Target</strong>: <span class="arithmatex">\(r + \gamma Q(s', a')\)</span> (one-step return using actual next action)</li>
<li><strong>Error</strong>: Difference between target and current estimate</li>
<li><strong>Update</strong>: Move current estimate toward target</li>
</ul>
<p><strong>Key property</strong>: On-policy learning (learns about the policy being executed).</p>
<hr />
<h3 id="12-rf-sarsa-functional-td-in-rkhs">1.2 RF-SARSA: Functional TD in RKHS<a class="headerlink" href="#12-rf-sarsa-functional-td-in-rkhs" title="Permanent link">&para;</a></h3>
<p>RF-SARSA maintains the TD learning principle but applies it to <strong>basis functions</strong> in RKHS, not to table entries.</p>
<p><strong>What changes</strong>:</p>
<ol>
<li><strong>Primary updates</strong>: Particle weights <span class="arithmatex">\(w_i\)</span> that define the field <span class="arithmatex">\(Q^+(z) = \sum_i w_i k(z, z_i)\)</span></li>
<li><strong>Geometric propagation</strong>: TD signal affects not just one location but a neighborhood (via kernel)</li>
<li><strong>Belief representation</strong>: The field <span class="arithmatex">\(Q^+\)</span> (equivalently, particle memory <span class="arithmatex">\(\Omega\)</span>) is the agent's state</li>
<li><strong>Action inference</strong>: Policy emerges from field queries, not direct optimization</li>
</ol>
<p><strong>Critical point</strong>: RF-SARSA is <strong>not</strong> learning a policyit's reshaping a landscape from which policy is inferred.</p>
<hr />
<h3 id="13-two-learning-processes-at-different-levels">1.3 Two Learning Processes at Different Levels<a class="headerlink" href="#13-two-learning-processes-at-different-levels" title="Permanent link">&para;</a></h3>
<p>RF-SARSA couples two learning processes:</p>
<p><strong>Primitive Layer</strong> (Discrete):</p>
<ul>
<li>Maintains <span class="arithmatex">\(Q(s, a)\)</span> estimates over discrete state-action pairs</li>
<li>Uses standard SARSA updates</li>
<li>Provides <strong>temporal grounding</strong> (immediate feedback from environment)</li>
<li>Supplies <strong>reinforcement signals</strong> (TD errors)</li>
</ul>
<p><strong>Field Layer</strong> (Continuous):</p>
<ul>
<li>Generalizes estimates over continuous augmented space <span class="arithmatex">\((s, \theta)\)</span></li>
<li>Uses Gaussian Process Regression (GPR) for interpolation</li>
<li>Performs <strong>policy inference</strong> exclusively</li>
<li>Receives <strong>reinforcement</strong> through experience particles</li>
</ul>
<p><strong>Key relationship</strong>:</p>
<ul>
<li>Primitive layer  generates TD evidence</li>
<li>Field layer  performs action inference</li>
<li>MemoryUpdate  connects them (Algorithm 1)</li>
</ul>
<hr />
<h2 id="2-the-rf-sarsa-algorithm-informal-overview">2. The RF-SARSA Algorithm (Informal Overview)<a class="headerlink" href="#2-the-rf-sarsa-algorithm-informal-overview" title="Permanent link">&para;</a></h2>
<p>Before the formal specification, here's the conceptual flow:</p>
<p><strong>Initialization</strong>:</p>
<ol>
<li>Initialize kernel hyperparameters <span class="arithmatex">\(\theta\)</span> (e.g., via ARD on initial particles)</li>
<li>Initialize primitive <span class="arithmatex">\(Q(s, a)\)</span> arbitrarily</li>
<li>Initialize particle memory <span class="arithmatex">\(\Omega\)</span> (possibly empty)</li>
</ol>
<p><strong>Each episode</strong>:</p>
<ol>
<li>Start in state <span class="arithmatex">\(s_0\)</span></li>
</ol>
<p><strong>Each step</strong>:</p>
<ol>
<li>
<p><strong>Field-based action inference</strong>:</p>
</li>
<li>
<p>For each candidate action <span class="arithmatex">\(a^{(i)}\)</span>, form augmented state <span class="arithmatex">\(z^{(i)} = (s, a^{(i)})\)</span></p>
</li>
<li>Query field: <span class="arithmatex">\(Q^+(z^{(i)}) = \mathbb{E}[Q^+ \mid \Omega, k, \theta]\)</span> via GPR</li>
<li>
<p>Select action via policy: <span class="arithmatex">\(a \sim \pi(a \mid s)\)</span> based on <span class="arithmatex">\(Q^+\)</span> values</p>
</li>
<li>
<p><strong>Environment interaction</strong>:</p>
</li>
<li>
<p>Execute <span class="arithmatex">\(a\)</span>, observe reward <span class="arithmatex">\(r\)</span> and next state <span class="arithmatex">\(s'\)</span></p>
</li>
<li>
<p><strong>Next action inference</strong>:</p>
</li>
<li>
<p>Repeat step 2 for state <span class="arithmatex">\(s'\)</span> to select <span class="arithmatex">\(a'\)</span></p>
</li>
<li>
<p><strong>Primitive SARSA update</strong>:</p>
</li>
<li>
<p>Compute TD error: <span class="arithmatex">\(\delta = r + \gamma Q(s', a') - Q(s, a)\)</span></p>
</li>
<li>
<p>Update: <span class="arithmatex">\(Q(s, a) \leftarrow Q(s, a) + \alpha \delta\)</span></p>
</li>
<li>
<p><strong>Particle reinforcement</strong> (Algorithm 1: MemoryUpdate):</p>
</li>
<li>
<p>Form particle: <span class="arithmatex">\(\omega = (z, Q(s, a))\)</span> where <span class="arithmatex">\(z = (s, a)\)</span></p>
</li>
<li>
<p>Update memory: <span class="arithmatex">\(\Omega \leftarrow \text{MemoryUpdate}(\omega, \delta, k, \tau, \Omega)\)</span></p>
</li>
<li>
<p><strong>Advance</strong>: <span class="arithmatex">\(s \leftarrow s'\)</span>, <span class="arithmatex">\(a \leftarrow a'\)</span></p>
</li>
</ol>
<p><strong>Periodic</strong>:</p>
<ul>
<li>Every <span class="arithmatex">\(T\)</span> steps, re-estimate kernel hyperparameters <span class="arithmatex">\(\theta\)</span> via ARD</li>
</ul>
<hr />
<h2 id="3-formal-specification">3. Formal Specification<a class="headerlink" href="#3-formal-specification" title="Permanent link">&para;</a></h2>
<h3 id="31-notation">3.1 Notation<a class="headerlink" href="#31-notation" title="Permanent link">&para;</a></h3>
<p><strong>Environment</strong>:</p>
<ul>
<li><span class="arithmatex">\(s \in \mathcal{S}\)</span>: primitive environment state</li>
<li><span class="arithmatex">\(a^{(i)} \in \mathcal{A}\)</span>: discrete action (<span class="arithmatex">\(i = 1, \ldots, n\)</span>)</li>
<li><span class="arithmatex">\(r \in \mathbb{R}\)</span>: reward</li>
<li><span class="arithmatex">\(\gamma \in [0, 1]\)</span>: discount factor</li>
</ul>
<p><strong>Parametric action representation</strong>:</p>
<ul>
<li><span class="arithmatex">\(M\)</span>: parametric action model</li>
<li><span class="arithmatex">\(f_{A^+}: a^{(i)} \mapsto x_a^{(i)} \in \mathbb{R}^{d_a}\)</span>: action encoder</li>
<li><span class="arithmatex">\(f_A: x_a \mapsto a\)</span>: action decoder</li>
</ul>
<p><strong>Augmented space</strong>:</p>
<ul>
<li><span class="arithmatex">\(x_s \in \mathbb{R}^{d_s}\)</span>: state features</li>
<li><span class="arithmatex">\(x_a \in \mathbb{R}^{d_a}\)</span>: action parameters</li>
<li><span class="arithmatex">\(z = (x_s, x_a) \in \mathbb{R}^{d_s + d_a}\)</span>: augmented state-action point</li>
</ul>
<p><strong>Value functions</strong>:</p>
<ul>
<li><span class="arithmatex">\(Q(s, a)\)</span>: primitive action-value (base SARSA learner)</li>
<li><span class="arithmatex">\(Q^+(z)\)</span>: field-based value estimate (via GPR on <span class="arithmatex">\(\Omega\)</span>)</li>
<li><span class="arithmatex">\(E(z) := -Q^+(z)\)</span>: energy (lower is better)</li>
</ul>
<p><strong>Memory and kernel</strong>:</p>
<ul>
<li><span class="arithmatex">\(\Omega = \{(z_i, q_i)\}_{i=1}^N\)</span>: particle memory (GPR training set)</li>
<li><span class="arithmatex">\(k(z, z'; \theta)\)</span>: kernel function with hyperparameters <span class="arithmatex">\(\theta\)</span></li>
<li><span class="arithmatex">\(\tau \in [0, 1]\)</span>: association threshold</li>
</ul>
<p><strong>Parameters</strong>:</p>
<ul>
<li><span class="arithmatex">\(\alpha\)</span>: SARSA learning rate</li>
<li><span class="arithmatex">\(T\)</span>: ARD update period</li>
<li><span class="arithmatex">\(\beta\)</span>: policy temperature (for Boltzmann policy)</li>
</ul>
<hr />
<h3 id="32-algorithm-rf-sarsa">3.2 Algorithm: RF-SARSA<a class="headerlink" href="#32-algorithm-rf-sarsa" title="Permanent link">&para;</a></h3>
<p><strong>Inputs</strong>:</p>
<ul>
<li>Kernel function <span class="arithmatex">\(k(\cdot, \cdot; \theta)\)</span></li>
<li>Parametric action model <span class="arithmatex">\(M\)</span></li>
<li>ARD update period <span class="arithmatex">\(T\)</span></li>
<li>Initial particle memory <span class="arithmatex">\(\Omega_0\)</span></li>
<li>Association threshold <span class="arithmatex">\(\tau\)</span></li>
<li>Learning rate <span class="arithmatex">\(\alpha\)</span>, discount <span class="arithmatex">\(\gamma\)</span>, policy temperature <span class="arithmatex">\(\beta\)</span></li>
</ul>
<p><strong>Initialization</strong>:</p>
<ol>
<li>
<p><strong>Estimate kernel hyperparameters</strong>:</p>
</li>
<li>
<p>If <span class="arithmatex">\(\Omega_0 \neq \emptyset\)</span>: Run ARD on <span class="arithmatex">\(\Omega_0\)</span> to get <span class="arithmatex">\(\theta\)</span></p>
</li>
<li>
<p>Else: Initialize <span class="arithmatex">\(\theta = \theta_0\)</span> from prior</p>
</li>
<li>
<p><strong>Initialize primitive Q-function</strong>:</p>
</li>
<li>
<p><span class="arithmatex">\(Q(s, a) \leftarrow 0\)</span> for all <span class="arithmatex">\((s, a)\)</span> (or small random values)</p>
</li>
<li>
<p><strong>Initialize particle memory</strong>:</p>
</li>
<li>
<p><span class="arithmatex">\(\Omega \leftarrow \Omega_0\)</span></p>
</li>
<li>
<p><strong>Initialize step counter</strong>:</p>
</li>
<li>
<p><span class="arithmatex">\(t_{\text{ARD}} \leftarrow 0\)</span></p>
</li>
</ol>
<hr />
<p><strong>For each episode</strong>:</p>
<ol>
<li>
<p><strong>Initialize state</strong>:</p>
</li>
<li>
<p>Observe initial state <span class="arithmatex">\(s_0\)</span></p>
</li>
<li>
<p>Set <span class="arithmatex">\(s \leftarrow s_0\)</span></p>
</li>
<li>
<p><strong>Initial action selection</strong>:</p>
</li>
<li>
<p>For each <span class="arithmatex">\(a^{(i)} \in \mathcal{A}\)</span>:</p>
<ul>
<li>Encode: <span class="arithmatex">\(x_a^{(i)} \leftarrow f_{A^+}(a^{(i)})\)</span></li>
<li>Form augmented: <span class="arithmatex">\(z^{(i)} \leftarrow (x_s(s), x_a^{(i)})\)</span></li>
<li>Field query: <span class="arithmatex">\(Q^+(z^{(i)}) \leftarrow \text{GPR-Predict}(z^{(i)}; \Omega, k, \theta)\)</span></li>
<li>Policy: <span class="arithmatex">\(a \sim \pi(\cdot \mid s)\)</span> where <span class="arithmatex">\(\pi(a^{(i)} \mid s) \propto \exp(\beta Q^+(z^{(i)}))\)</span></li>
</ul>
</li>
</ol>
<hr />
<p><strong>For each step of episode</strong>:</p>
<ol>
<li>
<p><strong>Periodic kernel hyperparameter update</strong>:</p>
</li>
<li>
<p>If <span class="arithmatex">\(t_{\text{ARD}} \bmod T = 0\)</span>:</p>
<ul>
<li>Re-run ARD on <span class="arithmatex">\(\Omega\)</span> to update <span class="arithmatex">\(\theta\)</span></li>
<li>(Optional) Increase <span class="arithmatex">\(T\)</span> to reduce update frequency over time</li>
<li><span class="arithmatex">\(t_{\text{ARD}} \leftarrow t_{\text{ARD}} + 1\)</span></li>
</ul>
</li>
<li>
<p><strong>Environment interaction</strong>:</p>
</li>
<li>
<p>Execute action <span class="arithmatex">\(a\)</span></p>
</li>
<li>
<p>Observe reward <span class="arithmatex">\(r\)</span> and next state <span class="arithmatex">\(s'\)</span></p>
</li>
<li>
<p><strong>Next action inference</strong> (field query):</p>
</li>
<li>
<p>For each <span class="arithmatex">\(a'^{(j)} \in \mathcal{A}\)</span>:</p>
<ul>
<li>Encode: <span class="arithmatex">\(x_a'^{(j)} \leftarrow f_{A^+}(a'^{(j)})\)</span></li>
<li>Form augmented: <span class="arithmatex">\(z'^{(j)} \leftarrow (x_s(s'), x_a'^{(j)})\)</span></li>
<li>Field query: <span class="arithmatex">\(Q^+(z'^{(j)}) \leftarrow \text{GPR-Predict}(z'^{(j)}; \Omega, k, \theta)\)</span></li>
<li>Policy: <span class="arithmatex">\(a' \sim \pi(\cdot \mid s')\)</span> where <span class="arithmatex">\(\pi(a'^{(j)} \mid s') \propto \exp(\beta Q^+(z'^{(j)}))\)</span></li>
</ul>
</li>
<li>
<p><strong>Primitive SARSA update</strong> (generates TD evidence):</p>
<ul>
<li>Compute TD error:
  $<span class="arithmatex">\(\delta \leftarrow r + \gamma Q(s', a') - Q(s, a)\)</span>$</li>
<li>Update primitive Q-function:
  $<span class="arithmatex">\(Q(s, a) \leftarrow Q(s, a) + \alpha \delta\)</span>$</li>
<li>Store updated value: <span class="arithmatex">\(q \leftarrow Q(s, a)\)</span></li>
</ul>
</li>
<li>
<p><strong>Particle reinforcement</strong> (Algorithm 1: MemoryUpdate):</p>
<ul>
<li>Form experience particle:
  $<span class="arithmatex">\(\omega \leftarrow (z, q) \quad \text{where} \quad z = (x_s(s), f_{A^+}(a))\)</span>$</li>
<li>Update particle memory:
  $<span class="arithmatex">\(\Omega \leftarrow \text{MemoryUpdate}(\omega, \delta, k, \tau, \Omega)\)</span>$
  (See Chapter 6 for MemoryUpdate details)</li>
</ul>
</li>
<li>
<p><strong>State-action transition</strong>:</p>
<ul>
<li><span class="arithmatex">\(s \leftarrow s'\)</span>, <span class="arithmatex">\(a \leftarrow a'\)</span></li>
</ul>
</li>
<li>
<p><strong>Termination check</strong>:</p>
<ul>
<li>If <span class="arithmatex">\(s\)</span> is terminal, end episode</li>
<li>Else, return to step 7</li>
</ul>
</li>
</ol>
<hr />
<h3 id="33-helper-function-gpr-predict">3.3 Helper Function: GPR-Predict<a class="headerlink" href="#33-helper-function-gpr-predict" title="Permanent link">&para;</a></h3>
<p><strong>Gaussian Process Regression prediction</strong>:</p>
<p>Given particle memory <span class="arithmatex">\(\Omega = \{(z_i, q_i)\}_{i=1}^N\)</span>, kernel <span class="arithmatex">\(k\)</span>, and hyperparameters <span class="arithmatex">\(\theta\)</span>, predict the field value at query point <span class="arithmatex">\(z\)</span>:</p>
<div class="arithmatex">\[Q^+(z) = \sum_{i=1}^N \alpha_i k(z, z_i; \theta)\]</div>
<p>where coefficients <span class="arithmatex">\(\alpha = (\alpha_1, \ldots, \alpha_N)^\top\)</span> solve:</p>
<div class="arithmatex">\[(K + \sigma_n^2 I) \alpha = q\]</div>
<p>with:</p>
<ul>
<li><span class="arithmatex">\(K_{ij} = k(z_i, z_j; \theta)\)</span>: kernel matrix</li>
<li><span class="arithmatex">\(q = (q_1, \ldots, q_N)^\top\)</span>: stored values</li>
<li><span class="arithmatex">\(\sigma_n^2\)</span>: noise variance (hyperparameter)</li>
</ul>
<p><strong>In practice</strong>: Use efficient GPR libraries (e.g., GPyTorch, scikit-learn's <code>GaussianProcessRegressor</code>).</p>
<p><strong>Computational note</strong>: For large <span class="arithmatex">\(N\)</span>, use sparse GP approximations (e.g., inducing points, random features).</p>
<hr />
<h2 id="4-how-rf-sarsa-works-the-three-forces">4. How RF-SARSA Works: The Three Forces<a class="headerlink" href="#4-how-rf-sarsa-works-the-three-forces" title="Permanent link">&para;</a></h2>
<p>RF-SARSA succeeds by balancing three forces:</p>
<h3 id="41-temporal-credit-assignment-primitive-sarsa">4.1 Temporal Credit Assignment (Primitive SARSA)<a class="headerlink" href="#41-temporal-credit-assignment-primitive-sarsa" title="Permanent link">&para;</a></h3>
<p><strong>Role</strong>: Ground the field in actual experienced returns.</p>
<p><strong>Mechanism</strong>: SARSA provides <strong>temporally accurate</strong> value estimates:</p>
<ul>
<li>TD error <span class="arithmatex">\(\delta = r + \gamma Q(s', a') - Q(s, a)\)</span> measures prediction error</li>
<li>Bootstrapping from <span class="arithmatex">\(Q(s', a')\)</span> propagates future returns backward</li>
<li>On-policy learning ensures values reflect the behavior policy</li>
</ul>
<p><strong>Why this matters</strong>: Without temporal grounding, the field would have no connection to true returnsit would generalize nonsense.</p>
<hr />
<h3 id="42-geometric-generalization-gpr">4.2 Geometric Generalization (GPR)<a class="headerlink" href="#42-geometric-generalization-gpr" title="Permanent link">&para;</a></h3>
<p><strong>Role</strong>: Spread value information across similar configurations.</p>
<p><strong>Mechanism</strong>: Kernel similarity defines "nearness":</p>
<ul>
<li><span class="arithmatex">\(k(z, z')\)</span> large  <span class="arithmatex">\(z\)</span> and <span class="arithmatex">\(z'\)</span> are similar  should have similar <span class="arithmatex">\(Q^+\)</span> values</li>
<li>GP regression interpolates smoothly between particles</li>
<li>Predictions come with uncertainty estimates (<span class="arithmatex">\(\sigma^2(z)\)</span>)</li>
</ul>
<p><strong>Why this matters</strong>: The agent visits a tiny fraction of augmented spacegeneralization is essential for learning.</p>
<hr />
<h3 id="43-adaptive-geometry-ard">4.3 Adaptive Geometry (ARD)<a class="headerlink" href="#43-adaptive-geometry-ard" title="Permanent link">&para;</a></h3>
<p><strong>Role</strong>: Learn which dimensions matter.</p>
<p><strong>Mechanism</strong>: Automatic Relevance Determination (ARD) adjusts kernel lengthscales:</p>
<ul>
<li>Large lengthscale  dimension is irrelevant  smooth over it</li>
<li>Small lengthscale  dimension is critical  pay attention to variations</li>
</ul>
<p><strong>Example</strong>: In a reaching task, gripper orientation might be irrelevant initially but critical when graspingARD adapts.</p>
<p><strong>Why this matters</strong>: The agent doesn't know a priori which action parameters are importantARD discovers this from data.</p>
<hr />
<h3 id="44-the-virtuous-cycle">4.4 The Virtuous Cycle<a class="headerlink" href="#44-the-virtuous-cycle" title="Permanent link">&para;</a></h3>
<p>These three forces create a virtuous cycle:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>1. SARSA updates primitive Q(s,a) using TD  accurate local estimates
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>2. Particles (z, Q(s,a)) added to   new training data
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>3. GPR generalizes across   smooth field Q+(z)
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>4. Policy queries Q+(z)  explores intelligently
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>5. New experiences  refine SARSA estimates
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>6. ARD adapts kernel  focuses on relevant dimensions
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a> Loop back to step 1
</span></code></pre></div>
<p><strong>Key insight</strong>: The field <span class="arithmatex">\(Q^+\)</span> is <strong>not optimized</strong>it <strong>emerges</strong> from the interaction of these forces.</p>
<hr />
<h2 id="5-connection-to-the-principle-of-least-action">5. Connection to the Principle of Least Action<a class="headerlink" href="#5-connection-to-the-principle-of-least-action" title="Permanent link">&para;</a></h2>
<p>With Chapter 03a fresh in mind, we can now see RF-SARSA through the lens of physics.</p>
<h3 id="51-rf-sarsa-as-action-minimization">5.1 RF-SARSA as Action Minimization<a class="headerlink" href="#51-rf-sarsa-as-action-minimization" title="Permanent link">&para;</a></h3>
<p>Recall from Chapter 03a that optimal trajectories minimize the action functional:</p>
<div class="arithmatex">\[S[\tau] = \int_0^T \left[E(z_t) + \frac{1}{2\lambda}\|\dot{z}_t\|^2\right] dt\]</div>
<p><strong>RF-SARSA implements this</strong>:</p>
<ol>
<li><strong>Energy term</strong>: <span class="arithmatex">\(E(z) = -Q^+(z)\)</span> is learned via TD updates</li>
<li>High <span class="arithmatex">\(Q^+\)</span>  low energy  good configuration</li>
<li>
<p>SARSA signals reshape <span class="arithmatex">\(Q^+\)</span> to reflect actual returns</p>
</li>
<li>
<p><strong>Kinetic term</strong>: <span class="arithmatex">\(\frac{1}{2\lambda}\|\dot{z}\|^2\)</span> is implicitly encoded by the kernel</p>
</li>
<li>Smooth kernels (e.g., RBF) penalize rapid changes</li>
<li>Particles propagate weights to neighbors (Algorithm 1: MemoryUpdate)</li>
<li>
<p>Result: Smooth <span class="arithmatex">\(Q^+\)</span> landscape</p>
</li>
<li>
<p><strong>Policy</strong>: Boltzmann distribution <span class="arithmatex">\(\pi \propto \exp(Q^+/\lambda)\)</span> minimizes expected action</p>
</li>
<li>Temperature <span class="arithmatex">\(\lambda\)</span> controls exploration</li>
<li>Sampling via Langevin dynamics (gradient flow on <span class="arithmatex">\(Q^+\)</span>)</li>
</ol>
<p><strong>The deep connection</strong>: RF-SARSA is not an ad-hoc algorithmit's <strong>learning the energy landscape</strong> from which the least-action principle determines optimal trajectories!</p>
<hr />
<h3 id="52-why-this-matters-for-learning">5.2 Why This Matters for Learning<a class="headerlink" href="#52-why-this-matters-for-learning" title="Permanent link">&para;</a></h3>
<p><strong>Smoothness as regularization</strong>:</p>
<ul>
<li>RF-SARSA favors smooth <span class="arithmatex">\(Q^+\)</span> fields (via kernel smoothness)</li>
<li>Equivalent to penalizing rapid action changes (kinetic term)</li>
<li>Natural Occam's razor: simple policies preferred</li>
</ul>
<p><strong>Physical intuition</strong>:</p>
<ul>
<li>Particles are like "mass distributions" creating a potential landscape</li>
<li>Agent follows "trajectories" that minimize action</li>
<li>MemoryUpdate reshapes the landscape based on experience</li>
</ul>
<p><strong>Modern perspective</strong>:</p>
<ul>
<li>This is <strong>energy-based learning</strong> (Chapter 3)</li>
<li>Policy emerges from <strong>gradient flow</strong> on learned energy (Langevin dynamics)</li>
<li>RF-SARSA anticipates modern score-based / diffusion-based RL methods</li>
</ul>
<hr />
<h2 id="6-worked-example-1d-navigation-continued">6. Worked Example: 1D Navigation (Continued)<a class="headerlink" href="#6-worked-example-1d-navigation-continued" title="Permanent link">&para;</a></h2>
<p>Let's extend the 1D navigation example from Chapter 6 to show how RF-SARSA learns.</p>
<h3 id="61-problem-setup">6.1 Problem Setup<a class="headerlink" href="#61-problem-setup" title="Permanent link">&para;</a></h3>
<p><strong>Environment</strong>:</p>
<ul>
<li>State <span class="arithmatex">\(s \in [0, 10]\)</span>: position on a line</li>
<li>Goal: <span class="arithmatex">\(s = 10\)</span> (reward <span class="arithmatex">\(r = +10\)</span>)</li>
<li>Obstacle: region <span class="arithmatex">\([4, 6]\)</span> (reward <span class="arithmatex">\(r = -5\)</span> if entered)</li>
<li>Actions: <span class="arithmatex">\(a \in \{\text{left}, \text{right}\}\)</span> with parametric "step size" <span class="arithmatex">\(\theta \in [0, 1]\)</span></li>
<li>left: <span class="arithmatex">\(s' = s - 2\theta\)</span></li>
<li>right: <span class="arithmatex">\(s' = s + 2\theta\)</span></li>
</ul>
<p><strong>Augmented space</strong>: <span class="arithmatex">\(z = (s, \theta) \in [0, 10] \times [0, 1]\)</span></p>
<p><strong>Kernel</strong>: RBF kernel <span class="arithmatex">\(k(z, z') = \exp(-\|z - z'\|^2 / (2\ell^2))\)</span> with lengthscale <span class="arithmatex">\(\ell = 0.5\)</span></p>
<hr />
<h3 id="62-initial-state-episode-1-step-1">6.2 Initial State (Episode 1, Step 1)<a class="headerlink" href="#62-initial-state-episode-1-step-1" title="Permanent link">&para;</a></h3>
<p><strong>Agent at <span class="arithmatex">\(s = 2\)</span></strong>:</p>
<p><strong>Primitive Q-function</strong> (initialized to zero):</p>
<ul>
<li><span class="arithmatex">\(Q(2, \text{left}) = 0\)</span></li>
<li><span class="arithmatex">\(Q(2, \text{right}) = 0\)</span></li>
</ul>
<p><strong>Particle memory</strong>: <span class="arithmatex">\(\Omega = \emptyset\)</span> (no particles yet)</p>
<p><strong>Field prediction</strong> (no particles  default prior mean = 0):</p>
<ul>
<li><span class="arithmatex">\(Q^+(2, \text{left}, 0.5) = 0\)</span></li>
<li><span class="arithmatex">\(Q^+(2, \text{right}, 0.5) = 0\)</span></li>
</ul>
<p><strong>Action selection</strong> (random, since all Q-values equal):</p>
<ul>
<li>Select <span class="arithmatex">\(a = \text{right}\)</span>, <span class="arithmatex">\(\theta = 0.5\)</span></li>
</ul>
<hr />
<h3 id="63-first-experience">6.3 First Experience<a class="headerlink" href="#63-first-experience" title="Permanent link">&para;</a></h3>
<p><strong>Execute action</strong>:</p>
<ul>
<li><span class="arithmatex">\(s' = 2 + 2(0.5) = 3\)</span>, <span class="arithmatex">\(r = 0\)</span> (no reward yet)</li>
</ul>
<p><strong>Next action</strong> (random again):</p>
<ul>
<li><span class="arithmatex">\(a' = \text{right}\)</span>, <span class="arithmatex">\(\theta' = 0.5\)</span></li>
</ul>
<p><strong>SARSA update</strong> (assume <span class="arithmatex">\(\gamma = 0.9\)</span>, <span class="arithmatex">\(\alpha = 0.1\)</span>):
$<span class="arithmatex">\(\delta = 0 + 0.9 \cdot 0 - 0 = 0\)</span>$
$<span class="arithmatex">\(Q(2, \text{right}) = 0 + 0.1 \cdot 0 = 0\)</span>$</p>
<p><strong>Particle</strong>: <span class="arithmatex">\(\omega = ((2, 0.5), 0)\)</span> (augmented state, updated Q-value)</p>
<p><strong>MemoryUpdate</strong>:</p>
<ul>
<li><span class="arithmatex">\(\Omega\)</span> is empty  create new particle</li>
<li><span class="arithmatex">\(\Omega = \{((2, 0.5), 0)\}\)</span></li>
</ul>
<p><strong>Field now</strong>: <span class="arithmatex">\(Q^+(z) = 0 \cdot k(z, (2, 0.5))\)</span> (still zero, but structure is building)</p>
<hr />
<h3 id="64-after-many-steps-goal-reached">6.4 After Many Steps: Goal Reached<a class="headerlink" href="#64-after-many-steps-goal-reached" title="Permanent link">&para;</a></h3>
<p><strong>Episode 1 concludes</strong>: Agent reaches <span class="arithmatex">\(s = 10\)</span> after 5 steps, receives <span class="arithmatex">\(r = +10\)</span>.</p>
<p><strong>Final step SARSA update</strong>:
$<span class="arithmatex">\(\delta = 10 + 0 - 0 = 10 \quad (\text{terminal, so } Q(s', a') = 0)\)</span>$
$<span class="arithmatex">\(Q(9, \text{right}) = 0 + 0.1 \cdot 10 = 1.0\)</span>$</p>
<p><strong>Particle</strong>: <span class="arithmatex">\(\omega = ((9, 0.5), 1.0)\)</span></p>
<p><strong>MemoryUpdate</strong>: Adds particle to <span class="arithmatex">\(\Omega\)</span>, propagates positive weight to neighbors.</p>
<p><strong>Key moment</strong>: Particles with positive values now exist near the goal!</p>
<hr />
<h3 id="65-episode-2-field-guided-exploration">6.5 Episode 2: Field-Guided Exploration<a class="headerlink" href="#65-episode-2-field-guided-exploration" title="Permanent link">&para;</a></h3>
<p><strong>Agent at <span class="arithmatex">\(s = 2\)</span> again</strong>:</p>
<p><strong>Field prediction</strong> (now informed by particles):</p>
<ul>
<li>Particles exist at <span class="arithmatex">\((9, 0.5)\)</span>, <span class="arithmatex">\((7, 0.5)\)</span>, etc. with positive weights</li>
<li><span class="arithmatex">\(Q^+(2, \text{right}, 0.5)\)</span> &gt; <span class="arithmatex">\(Q^+(2, \text{left}, 0.5)\)</span> (right leads toward goal)</li>
</ul>
<p><strong>Policy</strong>: Boltzmann with <span class="arithmatex">\(\beta = 1\)</span>:
$<span class="arithmatex">\(\pi(\text{right} \mid 2) = \frac{e^{Q^+(2, \text{right}, 0.5)}}{e^{Q^+(2, \text{right}, 0.5)} + e^{Q^+(2, \text{left}, 0.5)}}\)</span>$</p>
<p><strong>Result</strong>: Agent more likely to choose right (toward goal).</p>
<hr />
<h3 id="66-long-term-behavior">6.6 Long-Term Behavior<a class="headerlink" href="#66-long-term-behavior" title="Permanent link">&para;</a></h3>
<p><strong>After 100 episodes</strong>:</p>
<ul>
<li>Particle memory <span class="arithmatex">\(\Omega\)</span> contains ~500 particles</li>
<li>Positive-value particles cluster in paths leading to goal</li>
<li>Negative-value particles mark obstacle region</li>
<li>ARD has learned: position <span class="arithmatex">\(s\)</span> is critical, step size <span class="arithmatex">\(\theta\)</span> less so (larger lengthscale for <span class="arithmatex">\(\theta\)</span>)</li>
</ul>
<p><strong>Field <span class="arithmatex">\(Q^+\)</span></strong>:</p>
<ul>
<li>High values: paths from any <span class="arithmatex">\(s\)</span> toward goal, avoiding obstacle</li>
<li>Low values: paths toward obstacle or away from goal</li>
</ul>
<p><strong>Policy</strong>:</p>
<ul>
<li>Smooth, deterministic path from any start state to goal</li>
<li>Naturally avoids obstacle (low <span class="arithmatex">\(Q^+\)</span> region)</li>
</ul>
<p><strong>This is emergence</strong>: The agent never explicitly computed an optimal pathit emerged from RF-SARSA's three forces!</p>
<hr />
<h2 id="7-why-rf-sarsa-is-not-standard-sarsa-with-kernels">7. Why RF-SARSA Is NOT Standard SARSA with Kernels<a class="headerlink" href="#7-why-rf-sarsa-is-not-standard-sarsa-with-kernels" title="Permanent link">&para;</a></h2>
<h3 id="71-common-misconception">7.1 Common Misconception<a class="headerlink" href="#71-common-misconception" title="Permanent link">&para;</a></h3>
<p><strong> interpretation</strong>: "RF-SARSA is just SARSA using kernel function approximation instead of a table."</p>
<p><strong>Why this is wrong</strong>:</p>
<table>
<thead>
<tr>
<th>Aspect</th>
<th>Kernel Function Approximation</th>
<th>RF-SARSA</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Updates</strong></td>
<td>Global weight vector <span class="arithmatex">\(w\)</span> via SGD</td>
<td>Particle ensemble <span class="arithmatex">\(\Omega\)</span> via MemoryUpdate</td>
</tr>
<tr>
<td><strong>Prediction</strong></td>
<td><span class="arithmatex">\(Q(s,a) = w^\top \phi(s,a)\)</span> (linear)</td>
<td><span class="arithmatex">\(Q^+(z) = \sum_i \alpha_i k(z, z_i)\)</span> (GPR)</td>
</tr>
<tr>
<td><strong>Memory</strong></td>
<td>Fixed basis <span class="arithmatex">\(\phi\)</span></td>
<td>Growing/evolving particle set</td>
</tr>
<tr>
<td><strong>Geometry</strong></td>
<td>Fixed feature space</td>
<td>Adaptive (ARD on kernel)</td>
</tr>
</tbody>
</table>
<p><strong>Kernel FA</strong> learns a weight vector. <strong>RF-SARSA</strong> shapes a functional field.</p>
<hr />
<h3 id="72-what-rf-sarsa-actually-is">7.2 What RF-SARSA Actually Is<a class="headerlink" href="#72-what-rf-sarsa-actually-is" title="Permanent link">&para;</a></h3>
<p>RF-SARSA is closer to:</p>
<p><strong>Galerkin methods</strong> (functional analysis):</p>
<ul>
<li>Approximate solutions in a finite-dimensional subspace of an infinite-dimensional space</li>
<li>RF-SARSA: subspace spanned by kernel sections <span class="arithmatex">\(k(z_i, \cdot)\)</span></li>
</ul>
<p><strong>Interacting particle systems</strong> (statistical physics):</p>
<ul>
<li>Particles influence each other through pairwise interactions</li>
<li>RF-SARSA: MemoryUpdate propagates weights through kernel interactions</li>
</ul>
<p><strong>Energy-based models</strong> (modern ML):</p>
<ul>
<li>Learn energy function, sample from <span class="arithmatex">\(p \propto \exp(-E)\)</span></li>
<li>RF-SARSA: Learn <span class="arithmatex">\(E = -Q^+\)</span>, policy is Boltzmann distribution</li>
</ul>
<p><strong>Belief-state RL</strong> (POMDPs):</p>
<ul>
<li>Maintain belief over states, condition policy on belief</li>
<li>RF-SARSA: <span class="arithmatex">\(\Omega\)</span> is belief representation, policy conditioned on <span class="arithmatex">\(Q^+(\cdot; \Omega)\)</span></li>
</ul>
<hr />
<h2 id="8-relation-to-modern-rl-methods">8. Relation to Modern RL Methods<a class="headerlink" href="#8-relation-to-modern-rl-methods" title="Permanent link">&para;</a></h2>
<p>RF-SARSA anticipated several ideas that became mainstream later:</p>
<h3 id="81-kernel-temporal-difference-learning">8.1 Kernel Temporal Difference Learning<a class="headerlink" href="#81-kernel-temporal-difference-learning" title="Permanent link">&para;</a></h3>
<p><strong>Kernel TD</strong> (Engel et al., 2005):</p>
<ul>
<li>Apply TD learning in RKHS</li>
<li>Use kernel trick for function approximation</li>
</ul>
<p><strong>RF-SARSA connection</strong>:</p>
<ul>
<li>Also uses kernels for TD learning</li>
<li>But operates in augmented space <span class="arithmatex">\((s, \theta)\)</span></li>
<li>Couples with particle-based memory management</li>
</ul>
<hr />
<h3 id="82-energy-based-rl">8.2 Energy-Based RL<a class="headerlink" href="#82-energy-based-rl" title="Permanent link">&para;</a></h3>
<p><strong>Modern EBMs</strong> (e.g., Diffusion Q-learning, 2023):</p>
<ul>
<li>Represent policies/values as energy functions</li>
<li>Sampling via Langevin dynamics</li>
</ul>
<p><strong>RF-SARSA connection</strong>:</p>
<ul>
<li>Energy interpretation <span class="arithmatex">\(E = -Q^+\)</span> (Chapter 3)</li>
<li>Policy via Boltzmann distribution (Chapter 03a)</li>
<li>Implicitly performs gradient flow on learned energy</li>
</ul>
<hr />
<h3 id="83-model-based-rl-via-gps">8.3 Model-Based RL via GPs<a class="headerlink" href="#83-model-based-rl-via-gps" title="Permanent link">&para;</a></h3>
<p><strong>GP-based model learning</strong> (Deisenroth et al., 2015):</p>
<ul>
<li>Learn forward dynamics <span class="arithmatex">\(p(s' \mid s, a)\)</span> via GP</li>
<li>Plan using learned model</li>
</ul>
<p><strong>RF-SARSA connection</strong>:</p>
<ul>
<li>GP over augmented space provides implicit forward model</li>
<li>Soft state transitions emerge from kernel similarity (Chapter 8, upcoming)</li>
<li>No explicit dynamics model, but captures uncertainty</li>
</ul>
<hr />
<h3 id="84-neural-processes">8.4 Neural Processes<a class="headerlink" href="#84-neural-processes" title="Permanent link">&para;</a></h3>
<p><strong>Neural Processes</strong> (Garnelo et al., 2018):</p>
<ul>
<li>Learn a distribution over functions from context set</li>
<li>Condition predictions on context</li>
</ul>
<p><strong>RF-SARSA connection</strong>:</p>
<ul>
<li><span class="arithmatex">\(\Omega\)</span> is the context set (particle memory)</li>
<li><span class="arithmatex">\(Q^+(z; \Omega)\)</span> is the conditional prediction</li>
<li>GPR is a (non-parametric) neural process!</li>
</ul>
<hr />
<h2 id="9-implementation-notes">9. Implementation Notes<a class="headerlink" href="#9-implementation-notes" title="Permanent link">&para;</a></h2>
<h3 id="91-choosing-hyperparameters">9.1 Choosing Hyperparameters<a class="headerlink" href="#91-choosing-hyperparameters" title="Permanent link">&para;</a></h3>
<p><strong>Kernel lengthscale <span class="arithmatex">\(\ell\)</span></strong>:</p>
<ul>
<li>Too small: overfitting, no generalization</li>
<li>Too large: over-smoothing, loss of detail</li>
<li><strong>Solution</strong>: Use ARD to learn per-dimension lengthscales</li>
</ul>
<p><strong>Association threshold <span class="arithmatex">\(\tau\)</span></strong>:</p>
<ul>
<li>Too low: all particles associate, slow computation</li>
<li>Too high: no association, memory explosion</li>
<li><strong>Rule of thumb</strong>: <span class="arithmatex">\(\tau \approx 0.1\)</span> (10% correlation threshold)</li>
</ul>
<p><strong>SARSA learning rate <span class="arithmatex">\(\alpha\)</span></strong>:</p>
<ul>
<li>Standard RL tuning: start <span class="arithmatex">\(\alpha = 0.1\)</span>, decay over time</li>
<li>Should be larger than typical Q-learning (on-policy is more stable)</li>
</ul>
<p><strong>Policy temperature <span class="arithmatex">\(\beta\)</span></strong>:</p>
<ul>
<li>High <span class="arithmatex">\(\beta\)</span> (low temperature): greedy, exploitation</li>
<li>Low <span class="arithmatex">\(\beta\)</span> (high temperature): stochastic, exploration</li>
<li><strong>Schedule</strong>: Exponential decay, e.g., <span class="arithmatex">\(\beta_t = \beta_0 \cdot 1.01^t\)</span></li>
</ul>
<hr />
<h3 id="92-computational-complexity">9.2 Computational Complexity<a class="headerlink" href="#92-computational-complexity" title="Permanent link">&para;</a></h3>
<p><strong>Per-step costs</strong>:</p>
<ol>
<li><strong>Field query</strong> (policy inference): <span class="arithmatex">\(O(Nn)\)</span></li>
<li><span class="arithmatex">\(N\)</span>: number of particles</li>
<li><span class="arithmatex">\(n\)</span>: number of discrete actions</li>
<li>
<p>GPR prediction: <span class="arithmatex">\(O(N)\)</span> per query (after precomputing <span class="arithmatex">\((K + \sigma_n^2 I)^{-1}q\)</span>)</p>
</li>
<li>
<p><strong>MemoryUpdate</strong>: <span class="arithmatex">\(O(N)\)</span></p>
</li>
<li>Compute associations: <span class="arithmatex">\(O(N)\)</span></li>
<li>
<p>Update weights: <span class="arithmatex">\(O(|\mathcal{N}|)\)</span> where <span class="arithmatex">\(|\mathcal{N}| \ll N\)</span></p>
</li>
<li>
<p><strong>ARD</strong> (every <span class="arithmatex">\(T\)</span> steps): <span class="arithmatex">\(O(N^3)\)</span></p>
</li>
<li>Solve GP regression: <span class="arithmatex">\(O(N^3)\)</span> (matrix inversion)</li>
<li><strong>Mitigation</strong>: Use sparse GP methods, or increase <span class="arithmatex">\(T\)</span> over time</li>
</ol>
<p><strong>Total</strong>: <span class="arithmatex">\(O(Nn + N + N^3/T) \approx O(Nn)\)</span> for reasonable <span class="arithmatex">\(T\)</span>, <span class="arithmatex">\(N\)</span>.</p>
<p><strong>Scaling</strong>: For large <span class="arithmatex">\(N\)</span> (&gt;1000), use:</p>
<ul>
<li>Sparse GPs (inducing points)</li>
<li>Random Fourier features</li>
<li>Amortized inference (neural network)</li>
</ul>
<hr />
<h3 id="93-sparse-gp-approximations">9.3 Sparse GP Approximations<a class="headerlink" href="#93-sparse-gp-approximations" title="Permanent link">&para;</a></h3>
<p><strong>Problem</strong>: GP regression is <span class="arithmatex">\(O(N^3)\)</span> in number of particles.</p>
<p><strong>Solution</strong>: Sparse GP (Quionero-Candela &amp; Rasmussen, 2005):</p>
<ul>
<li>Choose <span class="arithmatex">\(M \ll N\)</span> inducing points</li>
<li>Approximate <span class="arithmatex">\(Q^+\)</span> using only these points</li>
<li>Reduces complexity to <span class="arithmatex">\(O(M^2 N)\)</span></li>
</ul>
<p><strong>In RF-SARSA</strong>:</p>
<ul>
<li>Select inducing points from particle memory (e.g., k-means)</li>
<li>Update inducing points periodically</li>
</ul>
<p><strong>Implementation</strong>: Use GPyTorch or GPflow with <code>InducingPointStrategy</code>.</p>
<hr />
<h3 id="94-python-pseudocode">9.4 Python Pseudocode<a class="headerlink" href="#94-python-pseudocode" title="Permanent link">&para;</a></h3>
<div class="language-python highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="k">class</span><span class="w"> </span><span class="nc">RFSARSA</span><span class="p">:</span>
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">action_model</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">tau</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">T_ard</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">kernel</span>  <span class="c1"># e.g., RBF kernel</span>
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">action_model</span> <span class="o">=</span> <span class="n">action_model</span>  <span class="c1"># encodes/decodes actions</span>
</span><span id="__span-1-5"><a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>  <span class="c1"># SARSA learning rate</span>
</span><span id="__span-1-6"><a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span>  <span class="c1"># discount</span>
</span><span id="__span-1-7"><a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span>  <span class="c1"># policy temperature</span>
</span><span id="__span-1-8"><a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">tau</span> <span class="o">=</span> <span class="n">tau</span>  <span class="c1"># association threshold</span>
</span><span id="__span-1-9"><a id="__codelineno-1-9" name="__codelineno-1-9" href="#__codelineno-1-9"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">T_ard</span> <span class="o">=</span> <span class="n">T_ard</span>  <span class="c1"># ARD period</span>
</span><span id="__span-1-10"><a id="__codelineno-1-10" name="__codelineno-1-10" href="#__codelineno-1-10"></a>
</span><span id="__span-1-11"><a id="__codelineno-1-11" name="__codelineno-1-11" href="#__codelineno-1-11"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">Q_table</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># primitive Q(s,a)</span>
</span><span id="__span-1-12"><a id="__codelineno-1-12" name="__codelineno-1-12" href="#__codelineno-1-12"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">particles</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># particle memory  = [(z, q), ...]</span>
</span><span id="__span-1-13"><a id="__codelineno-1-13" name="__codelineno-1-13" href="#__codelineno-1-13"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">t_ard</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="__span-1-14"><a id="__codelineno-1-14" name="__codelineno-1-14" href="#__codelineno-1-14"></a>
</span><span id="__span-1-15"><a id="__codelineno-1-15" name="__codelineno-1-15" href="#__codelineno-1-15"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">gpr_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
</span><span id="__span-1-16"><a id="__codelineno-1-16" name="__codelineno-1-16" href="#__codelineno-1-16"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict Q+(z) using GPR on particle memory.&quot;&quot;&quot;</span>
</span><span id="__span-1-17"><a id="__codelineno-1-17" name="__codelineno-1-17" href="#__codelineno-1-17"></a>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">particles</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="__span-1-18"><a id="__codelineno-1-18" name="__codelineno-1-18" href="#__codelineno-1-18"></a>            <span class="k">return</span> <span class="mf">0.0</span>  <span class="c1"># prior mean</span>
</span><span id="__span-1-19"><a id="__codelineno-1-19" name="__codelineno-1-19" href="#__codelineno-1-19"></a>
</span><span id="__span-1-20"><a id="__codelineno-1-20" name="__codelineno-1-20" href="#__codelineno-1-20"></a>        <span class="c1"># Kernel vector: k(z, z_i) for all particles</span>
</span><span id="__span-1-21"><a id="__codelineno-1-21" name="__codelineno-1-21" href="#__codelineno-1-21"></a>        <span class="n">k_vec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span><span class="p">])</span>
</span><span id="__span-1-22"><a id="__codelineno-1-22" name="__codelineno-1-22" href="#__codelineno-1-22"></a>
</span><span id="__span-1-23"><a id="__codelineno-1-23" name="__codelineno-1-23" href="#__codelineno-1-23"></a>        <span class="c1"># GPR prediction (assuming precomputed alpha coefficients)</span>
</span><span id="__span-1-24"><a id="__codelineno-1-24" name="__codelineno-1-24" href="#__codelineno-1-24"></a>        <span class="k">return</span> <span class="n">k_vec</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha_gpr</span>
</span><span id="__span-1-25"><a id="__codelineno-1-25" name="__codelineno-1-25" href="#__codelineno-1-25"></a>
</span><span id="__span-1-26"><a id="__codelineno-1-26" name="__codelineno-1-26" href="#__codelineno-1-26"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">actions</span><span class="p">):</span>
</span><span id="__span-1-27"><a id="__codelineno-1-27" name="__codelineno-1-27" href="#__codelineno-1-27"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Boltzmann policy over actions based on Q+ field.&quot;&quot;&quot;</span>
</span><span id="__span-1-28"><a id="__codelineno-1-28" name="__codelineno-1-28" href="#__codelineno-1-28"></a>        <span class="n">q_values</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="__span-1-29"><a id="__codelineno-1-29" name="__codelineno-1-29" href="#__codelineno-1-29"></a>        <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">actions</span><span class="p">:</span>
</span><span id="__span-1-30"><a id="__codelineno-1-30" name="__codelineno-1-30" href="#__codelineno-1-30"></a>            <span class="n">x_a</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
</span><span id="__span-1-31"><a id="__codelineno-1-31" name="__codelineno-1-31" href="#__codelineno-1-31"></a>            <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">s</span><span class="p">,</span> <span class="n">x_a</span><span class="p">])</span>
</span><span id="__span-1-32"><a id="__codelineno-1-32" name="__codelineno-1-32" href="#__codelineno-1-32"></a>            <span class="n">q_plus</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gpr_predict</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
</span><span id="__span-1-33"><a id="__codelineno-1-33" name="__codelineno-1-33" href="#__codelineno-1-33"></a>            <span class="n">q_values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">q_plus</span><span class="p">)</span>
</span><span id="__span-1-34"><a id="__codelineno-1-34" name="__codelineno-1-34" href="#__codelineno-1-34"></a>
</span><span id="__span-1-35"><a id="__codelineno-1-35" name="__codelineno-1-35" href="#__codelineno-1-35"></a>        <span class="n">q_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">q_values</span><span class="p">)</span>
</span><span id="__span-1-36"><a id="__codelineno-1-36" name="__codelineno-1-36" href="#__codelineno-1-36"></a>        <span class="n">probs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">*</span> <span class="n">q_values</span><span class="p">)</span>
</span><span id="__span-1-37"><a id="__codelineno-1-37" name="__codelineno-1-37" href="#__codelineno-1-37"></a>        <span class="n">probs</span> <span class="o">/=</span> <span class="n">probs</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span id="__span-1-38"><a id="__codelineno-1-38" name="__codelineno-1-38" href="#__codelineno-1-38"></a>
</span><span id="__span-1-39"><a id="__codelineno-1-39" name="__codelineno-1-39" href="#__codelineno-1-39"></a>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">actions</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">probs</span><span class="p">)</span>
</span><span id="__span-1-40"><a id="__codelineno-1-40" name="__codelineno-1-40" href="#__codelineno-1-40"></a>
</span><span id="__span-1-41"><a id="__codelineno-1-41" name="__codelineno-1-41" href="#__codelineno-1-41"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">s_next</span><span class="p">,</span> <span class="n">a_next</span><span class="p">):</span>
</span><span id="__span-1-42"><a id="__codelineno-1-42" name="__codelineno-1-42" href="#__codelineno-1-42"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;RF-SARSA update: primitive SARSA + MemoryUpdate.&quot;&quot;&quot;</span>
</span><span id="__span-1-43"><a id="__codelineno-1-43" name="__codelineno-1-43" href="#__codelineno-1-43"></a>        <span class="c1"># Primitive SARSA update</span>
</span><span id="__span-1-44"><a id="__codelineno-1-44" name="__codelineno-1-44" href="#__codelineno-1-44"></a>        <span class="n">q_current</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Q_table</span><span class="o">.</span><span class="n">get</span><span class="p">((</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">),</span> <span class="mf">0.0</span><span class="p">)</span>
</span><span id="__span-1-45"><a id="__codelineno-1-45" name="__codelineno-1-45" href="#__codelineno-1-45"></a>        <span class="n">q_next</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Q_table</span><span class="o">.</span><span class="n">get</span><span class="p">((</span><span class="n">s_next</span><span class="p">,</span> <span class="n">a_next</span><span class="p">),</span> <span class="mf">0.0</span><span class="p">)</span>
</span><span id="__span-1-46"><a id="__codelineno-1-46" name="__codelineno-1-46" href="#__codelineno-1-46"></a>
</span><span id="__span-1-47"><a id="__codelineno-1-47" name="__codelineno-1-47" href="#__codelineno-1-47"></a>        <span class="n">delta</span> <span class="o">=</span> <span class="n">r</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">q_next</span> <span class="o">-</span> <span class="n">q_current</span>
</span><span id="__span-1-48"><a id="__codelineno-1-48" name="__codelineno-1-48" href="#__codelineno-1-48"></a>        <span class="n">q_new</span> <span class="o">=</span> <span class="n">q_current</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">delta</span>
</span><span id="__span-1-49"><a id="__codelineno-1-49" name="__codelineno-1-49" href="#__codelineno-1-49"></a>
</span><span id="__span-1-50"><a id="__codelineno-1-50" name="__codelineno-1-50" href="#__codelineno-1-50"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">Q_table</span><span class="p">[(</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">)]</span> <span class="o">=</span> <span class="n">q_new</span>
</span><span id="__span-1-51"><a id="__codelineno-1-51" name="__codelineno-1-51" href="#__codelineno-1-51"></a>
</span><span id="__span-1-52"><a id="__codelineno-1-52" name="__codelineno-1-52" href="#__codelineno-1-52"></a>        <span class="c1"># Form particle</span>
</span><span id="__span-1-53"><a id="__codelineno-1-53" name="__codelineno-1-53" href="#__codelineno-1-53"></a>        <span class="n">x_a</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
</span><span id="__span-1-54"><a id="__codelineno-1-54" name="__codelineno-1-54" href="#__codelineno-1-54"></a>        <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">s</span><span class="p">,</span> <span class="n">x_a</span><span class="p">])</span>
</span><span id="__span-1-55"><a id="__codelineno-1-55" name="__codelineno-1-55" href="#__codelineno-1-55"></a>        <span class="n">particle</span> <span class="o">=</span> <span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">q_new</span><span class="p">)</span>
</span><span id="__span-1-56"><a id="__codelineno-1-56" name="__codelineno-1-56" href="#__codelineno-1-56"></a>
</span><span id="__span-1-57"><a id="__codelineno-1-57" name="__codelineno-1-57" href="#__codelineno-1-57"></a>        <span class="c1"># MemoryUpdate (Algorithm 1)</span>
</span><span id="__span-1-58"><a id="__codelineno-1-58" name="__codelineno-1-58" href="#__codelineno-1-58"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">particles</span> <span class="o">=</span> <span class="n">memory_update</span><span class="p">(</span>
</span><span id="__span-1-59"><a id="__codelineno-1-59" name="__codelineno-1-59" href="#__codelineno-1-59"></a>            <span class="n">particle</span><span class="p">,</span> <span class="n">delta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span>
</span><span id="__span-1-60"><a id="__codelineno-1-60" name="__codelineno-1-60" href="#__codelineno-1-60"></a>        <span class="p">)</span>
</span><span id="__span-1-61"><a id="__codelineno-1-61" name="__codelineno-1-61" href="#__codelineno-1-61"></a>
</span><span id="__span-1-62"><a id="__codelineno-1-62" name="__codelineno-1-62" href="#__codelineno-1-62"></a>        <span class="c1"># Periodic ARD update</span>
</span><span id="__span-1-63"><a id="__codelineno-1-63" name="__codelineno-1-63" href="#__codelineno-1-63"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">t_ard</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="__span-1-64"><a id="__codelineno-1-64" name="__codelineno-1-64" href="#__codelineno-1-64"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">t_ard</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">T_ard</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="__span-1-65"><a id="__codelineno-1-65" name="__codelineno-1-65" href="#__codelineno-1-65"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">update_kernel_hyperparameters</span><span class="p">()</span>
</span><span id="__span-1-66"><a id="__codelineno-1-66" name="__codelineno-1-66" href="#__codelineno-1-66"></a>
</span><span id="__span-1-67"><a id="__codelineno-1-67" name="__codelineno-1-67" href="#__codelineno-1-67"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">update_kernel_hyperparameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="__span-1-68"><a id="__codelineno-1-68" name="__codelineno-1-68" href="#__codelineno-1-68"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Run ARD to update kernel lengthscales.&quot;&quot;&quot;</span>
</span><span id="__span-1-69"><a id="__codelineno-1-69" name="__codelineno-1-69" href="#__codelineno-1-69"></a>        <span class="c1"># Extract (z, q) from particles</span>
</span><span id="__span-1-70"><a id="__codelineno-1-70" name="__codelineno-1-70" href="#__codelineno-1-70"></a>        <span class="n">Z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span><span class="p">])</span>
</span><span id="__span-1-71"><a id="__codelineno-1-71" name="__codelineno-1-71" href="#__codelineno-1-71"></a>        <span class="n">q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">p</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span><span class="p">])</span>
</span><span id="__span-1-72"><a id="__codelineno-1-72" name="__codelineno-1-72" href="#__codelineno-1-72"></a>
</span><span id="__span-1-73"><a id="__codelineno-1-73" name="__codelineno-1-73" href="#__codelineno-1-73"></a>        <span class="c1"># Fit GP with ARD (optimize lengthscales)</span>
</span><span id="__span-1-74"><a id="__codelineno-1-74" name="__codelineno-1-74" href="#__codelineno-1-74"></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.gaussian_process</span><span class="w"> </span><span class="kn">import</span> <span class="n">GaussianProcessRegressor</span>
</span><span id="__span-1-75"><a id="__codelineno-1-75" name="__codelineno-1-75" href="#__codelineno-1-75"></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.gaussian_process.kernels</span><span class="w"> </span><span class="kn">import</span> <span class="n">RBF</span>
</span><span id="__span-1-76"><a id="__codelineno-1-76" name="__codelineno-1-76" href="#__codelineno-1-76"></a>
</span><span id="__span-1-77"><a id="__codelineno-1-77" name="__codelineno-1-77" href="#__codelineno-1-77"></a>        <span class="n">kernel</span> <span class="o">=</span> <span class="n">RBF</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">Z</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">length_scale_bounds</span><span class="o">=</span><span class="p">(</span><span class="mf">1e-2</span><span class="p">,</span> <span class="mf">1e2</span><span class="p">))</span>
</span><span id="__span-1-78"><a id="__codelineno-1-78" name="__codelineno-1-78" href="#__codelineno-1-78"></a>        <span class="n">gp</span> <span class="o">=</span> <span class="n">GaussianProcessRegressor</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
</span><span id="__span-1-79"><a id="__codelineno-1-79" name="__codelineno-1-79" href="#__codelineno-1-79"></a>        <span class="n">gp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>
</span><span id="__span-1-80"><a id="__codelineno-1-80" name="__codelineno-1-80" href="#__codelineno-1-80"></a>
</span><span id="__span-1-81"><a id="__codelineno-1-81" name="__codelineno-1-81" href="#__codelineno-1-81"></a>        <span class="c1"># Update kernel with learned lengthscales</span>
</span><span id="__span-1-82"><a id="__codelineno-1-82" name="__codelineno-1-82" href="#__codelineno-1-82"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">set_lengthscales</span><span class="p">(</span><span class="n">gp</span><span class="o">.</span><span class="n">kernel_</span><span class="o">.</span><span class="n">length_scale</span><span class="p">)</span>
</span><span id="__span-1-83"><a id="__codelineno-1-83" name="__codelineno-1-83" href="#__codelineno-1-83"></a>
</span><span id="__span-1-84"><a id="__codelineno-1-84" name="__codelineno-1-84" href="#__codelineno-1-84"></a>        <span class="c1"># Recompute GPR coefficients</span>
</span><span id="__span-1-85"><a id="__codelineno-1-85" name="__codelineno-1-85" href="#__codelineno-1-85"></a>        <span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">Z</span><span class="p">)</span>
</span><span id="__span-1-86"><a id="__codelineno-1-86" name="__codelineno-1-86" href="#__codelineno-1-86"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">alpha_gpr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">K</span> <span class="o">+</span> <span class="mf">1e-6</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Z</span><span class="p">)),</span> <span class="n">q</span><span class="p">)</span>
</span></code></pre></div>
<hr />
<h2 id="10-strengths-and-limitations">10. Strengths and Limitations<a class="headerlink" href="#10-strengths-and-limitations" title="Permanent link">&para;</a></h2>
<h3 id="101-strengths">10.1 Strengths<a class="headerlink" href="#101-strengths" title="Permanent link">&para;</a></h3>
<p><strong>1. Generalization in Continuous Action Spaces</strong></p>
<ul>
<li>Natural handling of parametric actions</li>
<li>Smooth interpolation across action parameters</li>
</ul>
<p><strong>2. Uncertainty Quantification</strong></p>
<ul>
<li>GP provides variance <span class="arithmatex">\(\sigma^2(z)\)</span> (not shown above for simplicity)</li>
<li>Can guide exploration (e.g., UCB: <span class="arithmatex">\(Q^+ + \kappa \sigma\)</span>)</li>
</ul>
<p><strong>3. Adaptive Metric Learning</strong></p>
<ul>
<li>ARD discovers relevant dimensions automatically</li>
<li>No manual feature engineering required</li>
</ul>
<p><strong>4. Interpretability</strong></p>
<ul>
<li>Particles are interpretable (experienced configurations)</li>
<li>Field visualization shows value landscape</li>
</ul>
<p><strong>5. Theoretical Grounding</strong></p>
<ul>
<li>Connection to RKHS theory (Chapters 2, 4)</li>
<li>Least action principle (Chapter 03a)</li>
<li>POMDP interpretation (Chapter 8, upcoming)</li>
</ul>
<hr />
<h3 id="102-limitations">10.2 Limitations<a class="headerlink" href="#102-limitations" title="Permanent link">&para;</a></h3>
<p><strong>1. Computational Cost</strong></p>
<ul>
<li><span class="arithmatex">\(O(N^3)\)</span> for GP regression (ARD step)</li>
<li>Mitigated by sparse GPs, but still slower than deep RL</li>
</ul>
<p><strong>2. Memory Growth</strong></p>
<ul>
<li>Particle memory grows over time</li>
<li>Needs pruning/consolidation strategies (Chapter 06a)</li>
</ul>
<p><strong>3. Discrete Action Assumption</strong></p>
<ul>
<li>Algorithm as stated requires discrete action set for field queries</li>
<li><strong>Solution</strong>: Continuous optimization via Langevin sampling (Chapter 03a)</li>
</ul>
<p><strong>4. On-Policy Learning</strong></p>
<ul>
<li>SARSA is on-policy (learns about behavior policy)</li>
<li>Slower than off-policy (Q-learning, DQN)</li>
<li><strong>Tradeoff</strong>: More stable, safer for risk-sensitive domains</li>
</ul>
<p><strong>5. Hyperparameter Sensitivity</strong></p>
<ul>
<li>Requires tuning <span class="arithmatex">\(\alpha\)</span>, <span class="arithmatex">\(\beta\)</span>, <span class="arithmatex">\(\tau\)</span>, <span class="arithmatex">\(T\)</span></li>
<li>ARD helps but doesn't eliminate manual tuning</li>
</ul>
<hr />
<h2 id="11-summary">11. Summary<a class="headerlink" href="#11-summary" title="Permanent link">&para;</a></h2>
<h3 id="111-what-rf-sarsa-does">11.1 What RF-SARSA Does<a class="headerlink" href="#111-what-rf-sarsa-does" title="Permanent link">&para;</a></h3>
<p>RF-SARSA is <strong>not</strong> a policy learning algorithm. It is a <strong>functional reinforcement mechanism</strong> that:</p>
<ol>
<li><strong>Grounds</strong> value estimates temporally via primitive SARSA (<span class="arithmatex">\(Q(s,a)\)</span>)</li>
<li><strong>Generalizes</strong> them spatially via GP regression over particles (<span class="arithmatex">\(Q^+(z)\)</span>)</li>
<li><strong>Propagates</strong> them geometrically via MemoryUpdate (Algorithm 1)</li>
<li><strong>Adapts</strong> the metric via ARD (kernel hyperparameter learning)</li>
</ol>
<p><strong>Policy emerges</strong> as a consequence of this process (via field queries), not as its direct goal.</p>
<hr />
<h3 id="112-key-conceptual-insights">11.2 Key Conceptual Insights<a class="headerlink" href="#112-key-conceptual-insights" title="Permanent link">&para;</a></h3>
<p><strong>Two-layer architecture</strong>:</p>
<ul>
<li>Primitive layer (SARSA)  temporal grounding</li>
<li>Field layer (GPR)  spatial generalization</li>
</ul>
<p><strong>Belief-state interpretation</strong>:</p>
<ul>
<li>Particle memory <span class="arithmatex">\(\Omega\)</span> = agent's belief state</li>
<li>MemoryUpdate = belief update operator</li>
<li>Policy = belief-conditioned action inference</li>
</ul>
<p><strong>Physics grounding</strong>:</p>
<ul>
<li>Energy landscape <span class="arithmatex">\(E = -Q^+\)</span> learned from experience</li>
<li>Boltzmann policy minimizes expected action (Chapter 03a)</li>
<li>Smooth trajectories emerge from kinetic regularization (kernel smoothness)</li>
</ul>
<hr />
<h3 id="113-connection-to-the-big-picture">11.3 Connection to the Big Picture<a class="headerlink" href="#113-connection-to-the-big-picture" title="Permanent link">&para;</a></h3>
<p><strong>Part I: Reinforcement Fields</strong> (where we are now):</p>
<ul>
<li>Chapter 4: What is the reinforcement field? (functional object in RKHS)</li>
<li>Chapter 5: How is it represented? (particles as basis elements)</li>
<li>Chapter 6: How does memory evolve? (MemoryUpdate as belief transition)</li>
<li><strong>Chapter 7</strong> (this chapter): <strong>How is the field learned?</strong> (RF-SARSA as functional TD)</li>
</ul>
<p><strong>Coming next</strong>:</p>
<ul>
<li>Chapter 8: What emerges from this? (soft state transitions, uncertainty)</li>
<li>Chapter 9: How to interpret this? (POMDP view, belief-based control)</li>
<li>Chapter 10: Putting it all together (complete GRL system)</li>
</ul>
<hr />
<h2 id="12-key-takeaways">12. Key Takeaways<a class="headerlink" href="#12-key-takeaways" title="Permanent link">&para;</a></h2>
<ol>
<li>
<p><strong>RF-SARSA couples two learning processes</strong>: primitive SARSA (temporal grounding) + GPR (spatial generalization)</p>
</li>
<li>
<p><strong>It's not SARSA with kernels</strong>: Updates particle ensemble, not weight vector; reshapes functional field, not table entries</p>
</li>
<li>
<p><strong>Three forces enable learning</strong>: temporal credit (SARSA), geometric generalization (GP), adaptive geometry (ARD)</p>
</li>
<li>
<p><strong>Policy is inferred, not learned</strong>: Field queries via GPR  Boltzmann sampling  actions</p>
</li>
<li>
<p><strong>Physics-grounded</strong>: Energy landscape from least action principle; smooth trajectories from kinetic regularization</p>
</li>
<li>
<p><strong>Belief-state formulation</strong>: <span class="arithmatex">\(\Omega\)</span> is belief, MemoryUpdate is belief update, policy is belief-conditioned</p>
</li>
<li>
<p><strong>Scalable with approximations</strong>: Sparse GPs, random features, or neural networks for large-scale problems</p>
</li>
<li>
<p><strong>Anticipated modern methods</strong>: Kernel TD, energy-based RL, GP-based model RL, neural processes</p>
</li>
</ol>
<hr />
<h2 id="13-further-reading">13. Further Reading<a class="headerlink" href="#13-further-reading" title="Permanent link">&para;</a></h2>
<p><strong>Original RF-SARSA</strong>:</p>
<ul>
<li>Chiu &amp; Huber (2022), Section IV. <a href="https://arxiv.org/abs/2208.04822">arXiv:2208.04822</a></li>
</ul>
<p><strong>Kernel Temporal Difference Learning</strong>:</p>
<ul>
<li>Engel, Y., Mannor, S., &amp; Meir, R. (2005). "Reinforcement learning with Gaussian processes." <em>ICML</em>.</li>
<li>Xu, X., et al. (2007). "Kernel-based least squares policy iteration for reinforcement learning." <em>IEEE TNNLS</em>.</li>
</ul>
<p><strong>Path Integral Control (connection to Least Action)</strong>:</p>
<ul>
<li>Theodorou, E., Buchli, J., &amp; Schaal, S. (2010). "A generalized path integral control approach to reinforcement learning." <em>JMLR</em>.</li>
</ul>
<p><strong>Gaussian Processes for RL</strong>:</p>
<ul>
<li>Deisenroth, M. P., &amp; Rasmussen, C. E. (2011). "PILCO: A model-based and data-efficient approach to policy search." <em>ICML</em>.</li>
<li>Rasmussen, C. E., &amp; Williams, C. K. I. (2006). <em>Gaussian Processes for Machine Learning</em>. MIT Press.</li>
</ul>
<p><strong>Energy-Based RL</strong>:</p>
<ul>
<li>Haarnoja, T., et al. (2017). "Reinforcement learning with deep energy-based policies." <em>ICML</em> (SQL).</li>
<li>Ajay, A., et al. (2023). "Is conditional generative modeling all you need for decision making?" <em>ICLR</em> (Diffusion-QL).</li>
</ul>
<hr />
<p><strong><a href="../06a-advanced-memory-dynamics/"> Back to Chapter 06a: Advanced Memory Dynamics</a></strong> | <strong><a href="">Next: Chapter 08 (Coming Soon) </a></strong></p>
<p><strong><a href="../03a-least-action-principle/">Related: Chapter 03a - Least Action Principle</a></strong> | <strong><a href="../06-memory-update/">Related: Chapter 06 - MemoryUpdate</a></strong></p>
<p><strong><a href="../07a-continuous-policy-inference/">Supplement: Chapter 07a - Continuous Policy Inference</a></strong> | <strong><a href="../07b-rf-q-learning-and-convergence/">Supplement: Chapter 07b - RF-Q-Learning and the Deadly Triad</a></strong></p>
<hr />
<p><strong>Last Updated</strong>: January 14, 2026</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2026 GRL Research Team
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/pleiadian53/GRL" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../../..", "features": ["navigation.instant", "navigation.tracking", "navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.expand", "navigation.top", "search.suggest", "search.highlight", "content.code.copy", "content.action.edit"], "search": "../../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>